Even with only a single epoch, we were able to generate the following docstring: “Wrap an environment into a deepmind environment.” , with the True string being “ Configure environment for DeepMind-style Atari.” Even though it is not perfect, this is a promising result, as it shows that our model is able to generate a docstring that is both accurate and concise. We believe that with more training, our model could generate even more accurate and useful docstrings. Using a simple Evaluation: Score = (Number of overlapping words)/(Total Unique Words in Both strings) the score is 0.09 or 9%. Using Bleu evaluation, geometric mean of modified precision scores multiplied by a brevity penalty(Penalizes short candidate sentences) we are getting a 0.033 or a 3.3% and using rouge (Recall-Oriented Understudy for Gisting) Evaluation, which is focuses on recall, precision, and F-measure of n-gram overlaps, as well as longest common subsequences(rougeL): (rouge1, .285), (rouge2, 0), (rougeL, .285).
