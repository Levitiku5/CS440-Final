%        File: report.tex
%     Created: Tue Nov 12 05:00 PM 2024 M
% Last Change: Tue Nov 12 05:00 PM 2024 M
%

\documentclass[12pt]{article}
\usepackage{natbib}
\usepackage{hyperref}
\usepackage{amsmath}%
\usepackage{amsfonts}%
\usepackage{amssymb}%
\usepackage{graphicx}
\usepackage{enumitem}
%-------------------------------------------
\newtheorem{theorem}{Theorem}
\newtheorem{acknowledgement}[theorem]{Acknowledgement}
\newtheorem{algorithm}[theorem]{Algorithm}
\newtheorem{axiom}[theorem]{Axiom}
\newtheorem{case}[theorem]{Case}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{conclusion}[theorem]{Conclusion}
\newtheorem{condition}[theorem]{Condition}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{criterion}[theorem]{Criterion}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{exercise}[theorem]{Exercise}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{notation}[theorem]{Notation}
\newtheorem{problem}[theorem]{Problem}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{solution}[theorem]{Solution}
\newtheorem{summary}[theorem]{Summary}
\newenvironment{proof}[1][Proof]{\textbf{#1.} }{\ \rule{0.5em}{0.5em}}
\setlength{\textwidth}{7.0in}
\setlength{\oddsidemargin}{-0.35in}
\setlength{\topmargin}{-0.5in}
\setlength{\textheight}{9.0in}
\setlength{\parindent}{0.3in}

\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\U}{\mathbb{U}}

\usepackage{listings}
\usepackage{color}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
backgroundcolor=\color{backcolour},   
commentstyle=\color{codegreen},
keywordstyle=\color{magenta},
numberstyle=\tiny\color{codegray},
stringstyle=\color{codepurple},
basicstyle=\ttfamily\footnotesize,
breakatwhitespace=false,         
breaklines=true,                 
captionpos=b,                    
keepspaces=true,                 
numbers=left,                    
numbersep=5pt,                  
showspaces=false,                
showstringspaces=false,
showtabs=false,                  
tabsize=2
}

\lstset{style=mystyle}

\begin{document}
	\title{ AI-Generated Python Code Documentation: A Case Study }
	\author{Levi Shafter, Ryan Martel, Kevin Zhu}
	\maketitle

	\section*{Abstract}
	<++>

	\section{Introduction}
	\paragraph{} In an era of LLM-based revolution, many are exploring the endless possibilities of using artificial intelligence to aid in software development. This comes as no surprise considering the astounding need for software in nearly every aspect of modern industry. \cite{emerald2019csrImpact} With a dramatic increase in the need for software, some of the hottest topics being explored are the potential of enhancing the software development process, creating new tools as well as enhancing the old, and even automating certain aspects of writing code (See Section 3: Related Work). 
	\paragraph{} In this paper, we detail our experience with training a model using machine learning for the purpose of generating Python documentation. We discuss other similar works, compare our results, and discuss applications and potential improvements as well as viable future work. With so much recent progress in the field of AI \cite{shietal2020IoT_AI}, models like ours might drastically change the way we think about and approach software development.

	\section{Related Work}
	\paragraph{} Several recent studies and developments in the field of artificial intelligence and software development have highlighted significant advancements. These include the use of ML in resolving code review comments \cite{google2023codeReviewML}, the introduction of IDE plugins for AI-assisted development \cite{qodoAI2024idePlugin}, innovations in AI-powered fuzzing \cite{google2023aiFuzzing, cso2024aiFuzzing}, research into the out-of-distribution generalization of pre-trained language models \cite{chen2023oodGeneralization}, efforts in automated documentation with ChatGPT \cite{awekrx2024autodoc}, and the enhancement of large language models for multi-modal research synthesis \cite{wiggers2023largeModels}.


	\section{Method}
	For building our model, we used the following Python modules:
	\begin{itemize}
		\item datasets
		\item torch
		\item transformers
		\item accelerate
		\item evaluate
	\end{itemize}
	\paragraph{} For our dataset, we used the google/code\_x\_glue\_ct\_code\_to\_text dataset available here: https://huggingface.co/datasets/google/code\_x\_glue\_ct\_code\_to\_text. We made use of the RobertaTokenizer for preprocessing; specifically we began with the pretrained Salesforce/codet5-small model for some starting weights. Due to time constraints, we decided to skip the examples in the dataset so as to make our training time feasible on our hardware. To pad tokens, we used a value of -100 for our labels so as to avoid reduced model performance. 
	\paragraph{} We selected a batch size of 16 for our training dataset, and a batch size of 8 for both our validation and testing datasets so as to avoid running out of memory on our selected hardware. We then used the T5 model from the Hugging Face Transformers library to train our model on Colorado State University's computer science department machines. We decided to go with Roberta Tokenizer since it creates byte-level Byte-Pair-Encoding, suitable for our base model. Additionally, we used the accelerate library to speed up training. Finally, we used the evaluate library to evaluate our model.
	\paragraph{} We unfortunately found that higher values used as hyper parameters, particularly those used in the number of epochs, drastically increased our training time. With our limited time, we decided to move forward with a proof-of-concept using a number of epochs equal to one with zero warmup steps being used. Using CUDA, we trained our model primarily on our available GPUs using the AdamW optimizer.

	\section{Results}
	<++>

	\section{Discussion}
	<++>

	\section{Conclusion}
	<++>

	\section{Future Work}
	<++>

	\pagebreak
	\bibliographystyle{plain}
	\bibliography{refs}

\end{document}



