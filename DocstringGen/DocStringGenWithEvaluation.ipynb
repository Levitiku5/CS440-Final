{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40c5c38a-4aa9-4763-aff2-7743d1b339ef",
   "metadata": {},
   "source": [
    "Load the dataset and inspect properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09a27f4c-a7bc-421b-aa4e-6ca45ecf5119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: torch in /Users/kevinzhu/opt/anaconda3/lib/python3.9/site-packages (2.2.2)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.47.0-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-1.2.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: filelock in /Users/kevinzhu/opt/anaconda3/lib/python3.9/site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/kevinzhu/opt/anaconda3/lib/python3.9/site-packages (from datasets) (1.20.3)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Downloading pyarrow-18.1.0.tar.gz (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /Users/kevinzhu/opt/anaconda3/lib/python3.9/site-packages (from datasets) (1.4.1)\n",
      "Collecting requests>=2.32.2 (from datasets)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tqdm>=4.66.3 (from datasets)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp39-cp39-macosx_10_9_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py39-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Downloading aiohttp-3.11.10-cp39-cp39-macosx_10_9_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting huggingface-hub>=0.23.0 (from datasets)\n",
      "  Downloading huggingface_hub-0.26.3-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging in /Users/kevinzhu/opt/anaconda3/lib/python3.9/site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/kevinzhu/opt/anaconda3/lib/python3.9/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/kevinzhu/opt/anaconda3/lib/python3.9/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Users/kevinzhu/opt/anaconda3/lib/python3.9/site-packages (from torch) (1.9)\n",
      "Requirement already satisfied: networkx in /Users/kevinzhu/opt/anaconda3/lib/python3.9/site-packages (from torch) (2.6.3)\n",
      "Requirement already satisfied: jinja2 in /Users/kevinzhu/opt/anaconda3/lib/python3.9/site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/kevinzhu/opt/anaconda3/lib/python3.9/site-packages (from transformers) (2021.11.2)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.0-cp39-abi3-macosx_10_12_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.5-cp39-cp39-macosx_10_12_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: psutil in /Users/kevinzhu/opt/anaconda3/lib/python3.9/site-packages (from accelerate) (5.8.0)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets)\n",
      "  Using cached aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp->datasets)\n",
      "  Using cached async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/kevinzhu/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (21.4.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Using cached frozenlist-1.5.0-cp39-cp39-macosx_10_9_x86_64.whl.metadata (13 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Using cached multidict-6.1.0-cp39-cp39-macosx_10_9_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->datasets)\n",
      "  Using cached propcache-0.2.1-cp39-cp39-macosx_10_9_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets)\n",
      "  Using cached yarl-1.18.3-cp39-cp39-macosx_10_9_x86_64.whl.metadata (69 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/kevinzhu/opt/anaconda3/lib/python3.9/site-packages (from packaging->datasets) (3.0.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/kevinzhu/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/kevinzhu/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/kevinzhu/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/kevinzhu/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/kevinzhu/opt/anaconda3/lib/python3.9/site-packages (from jinja2->torch) (1.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/kevinzhu/opt/anaconda3/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/kevinzhu/opt/anaconda3/lib/python3.9/site-packages (from pandas->datasets) (2021.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/kevinzhu/opt/anaconda3/lib/python3.9/site-packages (from sympy->torch) (1.2.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/kevinzhu/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
      "Downloading transformers-4.47.0-py3-none-any.whl (10.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-1.2.0-py3-none-any.whl (336 kB)\n",
      "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "Downloading aiohttp-3.11.10-cp39-cp39-macosx_10_9_x86_64.whl (468 kB)\n",
      "Downloading huggingface_hub-0.26.3-py3-none-any.whl (447 kB)\n",
      "Downloading multiprocess-0.70.16-py39-none-any.whl (133 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading safetensors-0.4.5-cp39-cp39-macosx_10_12_x86_64.whl (393 kB)\n",
      "Downloading tokenizers-0.21.0-cp39-abi3-macosx_10_12_x86_64.whl (2.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading xxhash-3.5.0-cp39-cp39-macosx_10_9_x86_64.whl (31 kB)\n",
      "Using cached aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Using cached frozenlist-1.5.0-cp39-cp39-macosx_10_9_x86_64.whl (54 kB)\n",
      "Using cached multidict-6.1.0-cp39-cp39-macosx_10_9_x86_64.whl (29 kB)\n",
      "Using cached propcache-0.2.1-cp39-cp39-macosx_10_9_x86_64.whl (46 kB)\n",
      "Using cached yarl-1.18.3-cp39-cp39-macosx_10_9_x86_64.whl (94 kB)\n",
      "Building wheels for collected packages: pyarrow\n",
      "  Building wheel for pyarrow (pyproject.toml) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for pyarrow \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[784 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/orc.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/conftest.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_generated_version.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/benchmark.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_compute_docstrings.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/ipc.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/util.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/flight.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/cffi.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/substrait.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/__init__.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/types.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/dataset.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/cuda.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/feather.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/pandas_compat.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/fs.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/acero.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/csv.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/jvm.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/json.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/compute.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m running egg_info\n",
      "  \u001b[31m   \u001b[0m writing pyarrow.egg-info/PKG-INFO\n",
      "  \u001b[31m   \u001b[0m writing dependency_links to pyarrow.egg-info/dependency_links.txt\n",
      "  \u001b[31m   \u001b[0m writing requirements to pyarrow.egg-info/requires.txt\n",
      "  \u001b[31m   \u001b[0m writing top-level names to pyarrow.egg-info/top_level.txt\n",
      "  \u001b[31m   \u001b[0m ERROR setuptools_scm._file_finders.git listing git files failed - pretending there aren't any\n",
      "  \u001b[31m   \u001b[0m reading manifest file 'pyarrow.egg-info/SOURCES.txt'\n",
      "  \u001b[31m   \u001b[0m reading manifest template 'MANIFEST.in'\n",
      "  \u001b[31m   \u001b[0m warning: no files found matching '../LICENSE.txt'\n",
      "  \u001b[31m   \u001b[0m warning: no files found matching '../NOTICE.txt'\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*.so' found anywhere in distribution\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*.pyc' found anywhere in distribution\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*~' found anywhere in distribution\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '#*' found anywhere in distribution\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '.git*' found anywhere in distribution\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '.DS_Store' found anywhere in distribution\n",
      "  \u001b[31m   \u001b[0m no previously-included directories found matching '.asv'\n",
      "  \u001b[31m   \u001b[0m writing manifest file 'pyarrow.egg-info/SOURCES.txt'\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/cj/wlg4y4dn6ss8y1vg_fx2vth40000gn/T/pip-build-env-or4482yp/overlay/lib/python3.9/site-packages/setuptools/command/build_py.py:212: _Warning: Package 'pyarrow.includes' is absent from the `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         # Package would be ignored #\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         Python recognizes 'pyarrow.includes' as an importable package[^1],\n",
      "  \u001b[31m   \u001b[0m         but it is absent from setuptools' `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "  \u001b[31m   \u001b[0m         package, please make sure that 'pyarrow.includes' is explicitly added\n",
      "  \u001b[31m   \u001b[0m         to the `packages` configuration field.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         Alternatively, you can also rely on setuptools' discovery methods\n",
      "  \u001b[31m   \u001b[0m         (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "  \u001b[31m   \u001b[0m         instead of `find_packages(...)`/`find:`).\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package discovery\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         If you don't want 'pyarrow.includes' to be distributed and are\n",
      "  \u001b[31m   \u001b[0m         already explicitly excluding 'pyarrow.includes' via\n",
      "  \u001b[31m   \u001b[0m         `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "  \u001b[31m   \u001b[0m         you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "  \u001b[31m   \u001b[0m         combination with a more fine grained `package-data` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package data files\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "  \u001b[31m   \u001b[0m               even if it does not contain any `.py` files.\n",
      "  \u001b[31m   \u001b[0m               On the other hand, currently there is no concept of package data\n",
      "  \u001b[31m   \u001b[0m               directory, all directories are treated like packages.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   check.warn(importable)\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/cj/wlg4y4dn6ss8y1vg_fx2vth40000gn/T/pip-build-env-or4482yp/overlay/lib/python3.9/site-packages/setuptools/command/build_py.py:212: _Warning: Package 'pyarrow.interchange' is absent from the `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         # Package would be ignored #\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         Python recognizes 'pyarrow.interchange' as an importable package[^1],\n",
      "  \u001b[31m   \u001b[0m         but it is absent from setuptools' `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "  \u001b[31m   \u001b[0m         package, please make sure that 'pyarrow.interchange' is explicitly added\n",
      "  \u001b[31m   \u001b[0m         to the `packages` configuration field.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         Alternatively, you can also rely on setuptools' discovery methods\n",
      "  \u001b[31m   \u001b[0m         (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "  \u001b[31m   \u001b[0m         instead of `find_packages(...)`/`find:`).\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package discovery\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         If you don't want 'pyarrow.interchange' to be distributed and are\n",
      "  \u001b[31m   \u001b[0m         already explicitly excluding 'pyarrow.interchange' via\n",
      "  \u001b[31m   \u001b[0m         `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "  \u001b[31m   \u001b[0m         you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "  \u001b[31m   \u001b[0m         combination with a more fine grained `package-data` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package data files\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "  \u001b[31m   \u001b[0m               even if it does not contain any `.py` files.\n",
      "  \u001b[31m   \u001b[0m               On the other hand, currently there is no concept of package data\n",
      "  \u001b[31m   \u001b[0m               directory, all directories are treated like packages.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   check.warn(importable)\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/cj/wlg4y4dn6ss8y1vg_fx2vth40000gn/T/pip-build-env-or4482yp/overlay/lib/python3.9/site-packages/setuptools/command/build_py.py:212: _Warning: Package 'pyarrow.parquet' is absent from the `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         # Package would be ignored #\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         Python recognizes 'pyarrow.parquet' as an importable package[^1],\n",
      "  \u001b[31m   \u001b[0m         but it is absent from setuptools' `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "  \u001b[31m   \u001b[0m         package, please make sure that 'pyarrow.parquet' is explicitly added\n",
      "  \u001b[31m   \u001b[0m         to the `packages` configuration field.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         Alternatively, you can also rely on setuptools' discovery methods\n",
      "  \u001b[31m   \u001b[0m         (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "  \u001b[31m   \u001b[0m         instead of `find_packages(...)`/`find:`).\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package discovery\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         If you don't want 'pyarrow.parquet' to be distributed and are\n",
      "  \u001b[31m   \u001b[0m         already explicitly excluding 'pyarrow.parquet' via\n",
      "  \u001b[31m   \u001b[0m         `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "  \u001b[31m   \u001b[0m         you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "  \u001b[31m   \u001b[0m         combination with a more fine grained `package-data` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package data files\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "  \u001b[31m   \u001b[0m               even if it does not contain any `.py` files.\n",
      "  \u001b[31m   \u001b[0m               On the other hand, currently there is no concept of package data\n",
      "  \u001b[31m   \u001b[0m               directory, all directories are treated like packages.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   check.warn(importable)\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/cj/wlg4y4dn6ss8y1vg_fx2vth40000gn/T/pip-build-env-or4482yp/overlay/lib/python3.9/site-packages/setuptools/command/build_py.py:212: _Warning: Package 'pyarrow.src.arrow.python' is absent from the `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         # Package would be ignored #\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         Python recognizes 'pyarrow.src.arrow.python' as an importable package[^1],\n",
      "  \u001b[31m   \u001b[0m         but it is absent from setuptools' `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "  \u001b[31m   \u001b[0m         package, please make sure that 'pyarrow.src.arrow.python' is explicitly added\n",
      "  \u001b[31m   \u001b[0m         to the `packages` configuration field.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         Alternatively, you can also rely on setuptools' discovery methods\n",
      "  \u001b[31m   \u001b[0m         (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "  \u001b[31m   \u001b[0m         instead of `find_packages(...)`/`find:`).\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package discovery\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         If you don't want 'pyarrow.src.arrow.python' to be distributed and are\n",
      "  \u001b[31m   \u001b[0m         already explicitly excluding 'pyarrow.src.arrow.python' via\n",
      "  \u001b[31m   \u001b[0m         `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "  \u001b[31m   \u001b[0m         you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "  \u001b[31m   \u001b[0m         combination with a more fine grained `package-data` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package data files\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "  \u001b[31m   \u001b[0m               even if it does not contain any `.py` files.\n",
      "  \u001b[31m   \u001b[0m               On the other hand, currently there is no concept of package data\n",
      "  \u001b[31m   \u001b[0m               directory, all directories are treated like packages.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   check.warn(importable)\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/cj/wlg4y4dn6ss8y1vg_fx2vth40000gn/T/pip-build-env-or4482yp/overlay/lib/python3.9/site-packages/setuptools/command/build_py.py:212: _Warning: Package 'pyarrow.src.arrow.python.vendored' is absent from the `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         # Package would be ignored #\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         Python recognizes 'pyarrow.src.arrow.python.vendored' as an importable package[^1],\n",
      "  \u001b[31m   \u001b[0m         but it is absent from setuptools' `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "  \u001b[31m   \u001b[0m         package, please make sure that 'pyarrow.src.arrow.python.vendored' is explicitly added\n",
      "  \u001b[31m   \u001b[0m         to the `packages` configuration field.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         Alternatively, you can also rely on setuptools' discovery methods\n",
      "  \u001b[31m   \u001b[0m         (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "  \u001b[31m   \u001b[0m         instead of `find_packages(...)`/`find:`).\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package discovery\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         If you don't want 'pyarrow.src.arrow.python.vendored' to be distributed and are\n",
      "  \u001b[31m   \u001b[0m         already explicitly excluding 'pyarrow.src.arrow.python.vendored' via\n",
      "  \u001b[31m   \u001b[0m         `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "  \u001b[31m   \u001b[0m         you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "  \u001b[31m   \u001b[0m         combination with a more fine grained `package-data` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package data files\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "  \u001b[31m   \u001b[0m               even if it does not contain any `.py` files.\n",
      "  \u001b[31m   \u001b[0m               On the other hand, currently there is no concept of package data\n",
      "  \u001b[31m   \u001b[0m               directory, all directories are treated like packages.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   check.warn(importable)\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/cj/wlg4y4dn6ss8y1vg_fx2vth40000gn/T/pip-build-env-or4482yp/overlay/lib/python3.9/site-packages/setuptools/command/build_py.py:212: _Warning: Package 'pyarrow.tests' is absent from the `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         # Package would be ignored #\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         Python recognizes 'pyarrow.tests' as an importable package[^1],\n",
      "  \u001b[31m   \u001b[0m         but it is absent from setuptools' `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "  \u001b[31m   \u001b[0m         package, please make sure that 'pyarrow.tests' is explicitly added\n",
      "  \u001b[31m   \u001b[0m         to the `packages` configuration field.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         Alternatively, you can also rely on setuptools' discovery methods\n",
      "  \u001b[31m   \u001b[0m         (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "  \u001b[31m   \u001b[0m         instead of `find_packages(...)`/`find:`).\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package discovery\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         If you don't want 'pyarrow.tests' to be distributed and are\n",
      "  \u001b[31m   \u001b[0m         already explicitly excluding 'pyarrow.tests' via\n",
      "  \u001b[31m   \u001b[0m         `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "  \u001b[31m   \u001b[0m         you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "  \u001b[31m   \u001b[0m         combination with a more fine grained `package-data` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package data files\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "  \u001b[31m   \u001b[0m               even if it does not contain any `.py` files.\n",
      "  \u001b[31m   \u001b[0m               On the other hand, currently there is no concept of package data\n",
      "  \u001b[31m   \u001b[0m               directory, all directories are treated like packages.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   check.warn(importable)\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/cj/wlg4y4dn6ss8y1vg_fx2vth40000gn/T/pip-build-env-or4482yp/overlay/lib/python3.9/site-packages/setuptools/command/build_py.py:212: _Warning: Package 'pyarrow.tests.data.feather' is absent from the `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         # Package would be ignored #\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         Python recognizes 'pyarrow.tests.data.feather' as an importable package[^1],\n",
      "  \u001b[31m   \u001b[0m         but it is absent from setuptools' `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "  \u001b[31m   \u001b[0m         package, please make sure that 'pyarrow.tests.data.feather' is explicitly added\n",
      "  \u001b[31m   \u001b[0m         to the `packages` configuration field.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         Alternatively, you can also rely on setuptools' discovery methods\n",
      "  \u001b[31m   \u001b[0m         (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "  \u001b[31m   \u001b[0m         instead of `find_packages(...)`/`find:`).\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package discovery\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         If you don't want 'pyarrow.tests.data.feather' to be distributed and are\n",
      "  \u001b[31m   \u001b[0m         already explicitly excluding 'pyarrow.tests.data.feather' via\n",
      "  \u001b[31m   \u001b[0m         `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "  \u001b[31m   \u001b[0m         you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "  \u001b[31m   \u001b[0m         combination with a more fine grained `package-data` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package data files\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "  \u001b[31m   \u001b[0m               even if it does not contain any `.py` files.\n",
      "  \u001b[31m   \u001b[0m               On the other hand, currently there is no concept of package data\n",
      "  \u001b[31m   \u001b[0m               directory, all directories are treated like packages.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   check.warn(importable)\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/cj/wlg4y4dn6ss8y1vg_fx2vth40000gn/T/pip-build-env-or4482yp/overlay/lib/python3.9/site-packages/setuptools/command/build_py.py:212: _Warning: Package 'pyarrow.tests.data.orc' is absent from the `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         # Package would be ignored #\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         Python recognizes 'pyarrow.tests.data.orc' as an importable package[^1],\n",
      "  \u001b[31m   \u001b[0m         but it is absent from setuptools' `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "  \u001b[31m   \u001b[0m         package, please make sure that 'pyarrow.tests.data.orc' is explicitly added\n",
      "  \u001b[31m   \u001b[0m         to the `packages` configuration field.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         Alternatively, you can also rely on setuptools' discovery methods\n",
      "  \u001b[31m   \u001b[0m         (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "  \u001b[31m   \u001b[0m         instead of `find_packages(...)`/`find:`).\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package discovery\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         If you don't want 'pyarrow.tests.data.orc' to be distributed and are\n",
      "  \u001b[31m   \u001b[0m         already explicitly excluding 'pyarrow.tests.data.orc' via\n",
      "  \u001b[31m   \u001b[0m         `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "  \u001b[31m   \u001b[0m         you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "  \u001b[31m   \u001b[0m         combination with a more fine grained `package-data` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package data files\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "  \u001b[31m   \u001b[0m               even if it does not contain any `.py` files.\n",
      "  \u001b[31m   \u001b[0m               On the other hand, currently there is no concept of package data\n",
      "  \u001b[31m   \u001b[0m               directory, all directories are treated like packages.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   check.warn(importable)\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/cj/wlg4y4dn6ss8y1vg_fx2vth40000gn/T/pip-build-env-or4482yp/overlay/lib/python3.9/site-packages/setuptools/command/build_py.py:212: _Warning: Package 'pyarrow.tests.data.parquet' is absent from the `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         # Package would be ignored #\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         Python recognizes 'pyarrow.tests.data.parquet' as an importable package[^1],\n",
      "  \u001b[31m   \u001b[0m         but it is absent from setuptools' `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "  \u001b[31m   \u001b[0m         package, please make sure that 'pyarrow.tests.data.parquet' is explicitly added\n",
      "  \u001b[31m   \u001b[0m         to the `packages` configuration field.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         Alternatively, you can also rely on setuptools' discovery methods\n",
      "  \u001b[31m   \u001b[0m         (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "  \u001b[31m   \u001b[0m         instead of `find_packages(...)`/`find:`).\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package discovery\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         If you don't want 'pyarrow.tests.data.parquet' to be distributed and are\n",
      "  \u001b[31m   \u001b[0m         already explicitly excluding 'pyarrow.tests.data.parquet' via\n",
      "  \u001b[31m   \u001b[0m         `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "  \u001b[31m   \u001b[0m         you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "  \u001b[31m   \u001b[0m         combination with a more fine grained `package-data` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package data files\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "  \u001b[31m   \u001b[0m               even if it does not contain any `.py` files.\n",
      "  \u001b[31m   \u001b[0m               On the other hand, currently there is no concept of package data\n",
      "  \u001b[31m   \u001b[0m               directory, all directories are treated like packages.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   check.warn(importable)\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/cj/wlg4y4dn6ss8y1vg_fx2vth40000gn/T/pip-build-env-or4482yp/overlay/lib/python3.9/site-packages/setuptools/command/build_py.py:212: _Warning: Package 'pyarrow.tests.interchange' is absent from the `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         # Package would be ignored #\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         Python recognizes 'pyarrow.tests.interchange' as an importable package[^1],\n",
      "  \u001b[31m   \u001b[0m         but it is absent from setuptools' `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "  \u001b[31m   \u001b[0m         package, please make sure that 'pyarrow.tests.interchange' is explicitly added\n",
      "  \u001b[31m   \u001b[0m         to the `packages` configuration field.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         Alternatively, you can also rely on setuptools' discovery methods\n",
      "  \u001b[31m   \u001b[0m         (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "  \u001b[31m   \u001b[0m         instead of `find_packages(...)`/`find:`).\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package discovery\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         If you don't want 'pyarrow.tests.interchange' to be distributed and are\n",
      "  \u001b[31m   \u001b[0m         already explicitly excluding 'pyarrow.tests.interchange' via\n",
      "  \u001b[31m   \u001b[0m         `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "  \u001b[31m   \u001b[0m         you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "  \u001b[31m   \u001b[0m         combination with a more fine grained `package-data` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package data files\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "  \u001b[31m   \u001b[0m               even if it does not contain any `.py` files.\n",
      "  \u001b[31m   \u001b[0m               On the other hand, currently there is no concept of package data\n",
      "  \u001b[31m   \u001b[0m               directory, all directories are treated like packages.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   check.warn(importable)\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/cj/wlg4y4dn6ss8y1vg_fx2vth40000gn/T/pip-build-env-or4482yp/overlay/lib/python3.9/site-packages/setuptools/command/build_py.py:212: _Warning: Package 'pyarrow.tests.parquet' is absent from the `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         # Package would be ignored #\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         Python recognizes 'pyarrow.tests.parquet' as an importable package[^1],\n",
      "  \u001b[31m   \u001b[0m         but it is absent from setuptools' `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "  \u001b[31m   \u001b[0m         package, please make sure that 'pyarrow.tests.parquet' is explicitly added\n",
      "  \u001b[31m   \u001b[0m         to the `packages` configuration field.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         Alternatively, you can also rely on setuptools' discovery methods\n",
      "  \u001b[31m   \u001b[0m         (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "  \u001b[31m   \u001b[0m         instead of `find_packages(...)`/`find:`).\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package discovery\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         If you don't want 'pyarrow.tests.parquet' to be distributed and are\n",
      "  \u001b[31m   \u001b[0m         already explicitly excluding 'pyarrow.tests.parquet' via\n",
      "  \u001b[31m   \u001b[0m         `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "  \u001b[31m   \u001b[0m         you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "  \u001b[31m   \u001b[0m         combination with a more fine grained `package-data` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package data files\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "  \u001b[31m   \u001b[0m               even if it does not contain any `.py` files.\n",
      "  \u001b[31m   \u001b[0m               On the other hand, currently there is no concept of package data\n",
      "  \u001b[31m   \u001b[0m               directory, all directories are treated like packages.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   check.warn(importable)\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/cj/wlg4y4dn6ss8y1vg_fx2vth40000gn/T/pip-build-env-or4482yp/overlay/lib/python3.9/site-packages/setuptools/command/build_py.py:212: _Warning: Package 'pyarrow.vendored' is absent from the `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         # Package would be ignored #\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         Python recognizes 'pyarrow.vendored' as an importable package[^1],\n",
      "  \u001b[31m   \u001b[0m         but it is absent from setuptools' `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "  \u001b[31m   \u001b[0m         package, please make sure that 'pyarrow.vendored' is explicitly added\n",
      "  \u001b[31m   \u001b[0m         to the `packages` configuration field.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         Alternatively, you can also rely on setuptools' discovery methods\n",
      "  \u001b[31m   \u001b[0m         (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "  \u001b[31m   \u001b[0m         instead of `find_packages(...)`/`find:`).\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package discovery\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         If you don't want 'pyarrow.vendored' to be distributed and are\n",
      "  \u001b[31m   \u001b[0m         already explicitly excluding 'pyarrow.vendored' via\n",
      "  \u001b[31m   \u001b[0m         `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "  \u001b[31m   \u001b[0m         you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "  \u001b[31m   \u001b[0m         combination with a more fine grained `package-data` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package data files\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "  \u001b[31m   \u001b[0m               even if it does not contain any `.py` files.\n",
      "  \u001b[31m   \u001b[0m               On the other hand, currently there is no concept of package data\n",
      "  \u001b[31m   \u001b[0m               directory, all directories are treated like packages.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   check.warn(importable)\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/__init__.pxd -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_acero.pxd -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_acero.pyx -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_azurefs.pyx -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_compute.pxd -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_compute.pyx -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_csv.pxd -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_csv.pyx -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_cuda.pxd -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_cuda.pyx -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_dataset.pxd -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_dataset.pyx -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_dataset_orc.pyx -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_dataset_parquet.pxd -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_dataset_parquet.pyx -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_dataset_parquet_encryption.pyx -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_dlpack.pxi -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_feather.pyx -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_flight.pyx -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_fs.pxd -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_fs.pyx -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_gcsfs.pyx -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_hdfs.pyx -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_json.pxd -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_json.pyx -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_orc.pxd -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_orc.pyx -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_parquet.pxd -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_parquet.pyx -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_parquet_encryption.pxd -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_parquet_encryption.pyx -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_pyarrow_cpp_tests.pxd -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_pyarrow_cpp_tests.pyx -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_s3fs.pyx -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_substrait.pyx -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/array.pxi -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/benchmark.pxi -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/builder.pxi -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/compat.pxi -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/config.pxi -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/device.pxi -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/error.pxi -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/gandiva.pyx -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/io.pxi -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/ipc.pxi -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/lib.pxd -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/lib.pyx -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/memory.pxi -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/pandas-shim.pxi -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/public-api.pxi -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/scalar.pxi -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/table.pxi -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tensor.pxi -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/types.pxi -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/includes\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/includes/__init__.pxd -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/includes\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/includes/common.pxd -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/includes\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/includes/libarrow.pxd -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/includes\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/includes/libarrow_acero.pxd -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/includes\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/includes/libarrow_cuda.pxd -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/includes\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/includes/libarrow_dataset.pxd -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/includes\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/includes/libarrow_dataset_parquet.pxd -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/includes\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/includes/libarrow_feather.pxd -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/includes\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/includes/libarrow_flight.pxd -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/includes\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/includes/libarrow_fs.pxd -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/includes\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/includes/libarrow_python.pxd -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/includes\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/includes/libarrow_substrait.pxd -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/includes\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/includes/libgandiva.pxd -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/includes\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/includes/libparquet_encryption.pxd -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/includes\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/interchange\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/interchange/__init__.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/interchange\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/interchange/buffer.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/interchange\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/interchange/column.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/interchange\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/interchange/dataframe.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/interchange\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/interchange/from_dataframe.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/interchange\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/parquet/__init__.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/parquet/core.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/parquet/encryption.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/parquet\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/CMakeLists.txt -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/api.h -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/arrow_to_pandas.cc -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/arrow_to_pandas.h -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/arrow_to_python_internal.h -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/async.h -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/benchmark.cc -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/benchmark.h -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/common.cc -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/common.h -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/csv.cc -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/csv.h -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/datetime.cc -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/datetime.h -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/decimal.cc -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/decimal.h -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/deserialize.cc -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/deserialize.h -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/extension_type.cc -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/extension_type.h -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/filesystem.cc -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/filesystem.h -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/flight.cc -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/flight.h -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/gdb.cc -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/gdb.h -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/helpers.cc -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/helpers.h -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/inference.cc -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/inference.h -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/io.cc -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/io.h -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/ipc.cc -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/ipc.h -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/iterators.h -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/numpy_convert.cc -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/numpy_convert.h -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/numpy_init.cc -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/numpy_init.h -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/numpy_internal.h -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/numpy_interop.h -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/numpy_to_arrow.cc -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/numpy_to_arrow.h -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/parquet_encryption.cc -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/parquet_encryption.h -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/pch.h -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/platform.h -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/pyarrow.cc -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/pyarrow.h -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/pyarrow_api.h -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/pyarrow_lib.h -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/python_test.cc -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/python_test.h -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/python_to_arrow.cc -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/python_to_arrow.h -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/serialize.cc -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/serialize.h -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/type_traits.h -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/udf.cc -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/udf.h -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/visibility.h -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/src/arrow/python/vendored\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/vendored/CMakeLists.txt -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/src/arrow/python/vendored\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/vendored/pythoncapi_compat.h -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/src/arrow/python/vendored\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/__init__.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/arrow_16597.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/arrow_39313.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/arrow_7980.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/bound_function_visit_strings.pyx -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/conftest.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/extensions.pyx -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/pandas_examples.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/pandas_threaded_import.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/pyarrow_cython_example.pyx -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/read_record_batch.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/strategies.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_acero.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_adhoc_memory_leak.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_array.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_builder.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_cffi.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_compute.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_convert_builtin.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_cpp_internals.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_csv.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_cuda.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_cuda_numba_interop.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_cython.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_dataset.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_dataset_encryption.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_deprecations.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_device.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_dlpack.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_exec_plan.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_extension_type.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_feather.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_flight.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_flight_async.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_fs.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_gandiva.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_gdb.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_io.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_ipc.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_json.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_jvm.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_memory.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_misc.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_orc.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_pandas.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_scalars.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_schema.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_sparse_tensor.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_strategies.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_substrait.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_table.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_tensor.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_types.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_udf.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_util.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_without_numpy.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/util.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/wsgi_examples.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests/data/feather\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/data/feather/v0.17.0.version.2-compression.lz4.feather -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests/data/feather\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests/data/orc\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/data/orc/README.md -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests/data/orc\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/data/orc/TestOrcFile.emptyFile.jsn.gz -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests/data/orc\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/data/orc/TestOrcFile.emptyFile.orc -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests/data/orc\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/data/orc/TestOrcFile.test1.jsn.gz -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests/data/orc\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/data/orc/TestOrcFile.test1.orc -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests/data/orc\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/data/orc/TestOrcFile.testDate1900.jsn.gz -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests/data/orc\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/data/orc/TestOrcFile.testDate1900.orc -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests/data/orc\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/data/orc/decimal.jsn.gz -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests/data/orc\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/data/orc/decimal.orc -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests/data/orc\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests/data/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/data/parquet/v0.7.1.all-named-index.parquet -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests/data/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/data/parquet/v0.7.1.column-metadata-handling.parquet -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests/data/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/data/parquet/v0.7.1.parquet -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests/data/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/data/parquet/v0.7.1.some-named-index.parquet -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests/data/parquet\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests/interchange\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/interchange/__init__.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests/interchange\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/interchange/test_conversion.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests/interchange\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/interchange/test_interchange_spec.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests/interchange\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/parquet/__init__.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/parquet/common.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/parquet/conftest.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/parquet/encryption.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/parquet/test_basic.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/parquet/test_compliant_nested_type.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/parquet/test_data_types.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/parquet/test_dataset.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/parquet/test_datetime.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/parquet/test_encryption.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/parquet/test_metadata.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/parquet/test_pandas.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/parquet/test_parquet_file.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/parquet/test_parquet_writer.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/tests/parquet\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/vendored\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/vendored/__init__.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/vendored\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/vendored/docscrape.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/vendored\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/vendored/version.py -> build/lib.macosx-10.9-x86_64-cpython-39/pyarrow/vendored\n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m creating /private/var/folders/cj/wlg4y4dn6ss8y1vg_fx2vth40000gn/T/pip-install-e3f8ho5n/pyarrow_62ecca3cc57241d792824cd84cf8cbf4/build/temp.macosx-10.9-x86_64-cpython-39\n",
      "  \u001b[31m   \u001b[0m -- Running cmake for PyArrow\n",
      "  \u001b[31m   \u001b[0m cmake -DCMAKE_INSTALL_PREFIX=/private/var/folders/cj/wlg4y4dn6ss8y1vg_fx2vth40000gn/T/pip-install-e3f8ho5n/pyarrow_62ecca3cc57241d792824cd84cf8cbf4/build/lib.macosx-10.9-x86_64-cpython-39/pyarrow -DPYTHON_EXECUTABLE=/Users/kevinzhu/opt/anaconda3/bin/python -DPython3_EXECUTABLE=/Users/kevinzhu/opt/anaconda3/bin/python -DPYARROW_CXXFLAGS= -DPYARROW_BUNDLE_ARROW_CPP=off -DPYARROW_BUNDLE_CYTHON_CPP=off -DPYARROW_GENERATE_COVERAGE=off -DCMAKE_BUILD_TYPE=release /private/var/folders/cj/wlg4y4dn6ss8y1vg_fx2vth40000gn/T/pip-install-e3f8ho5n/pyarrow_62ecca3cc57241d792824cd84cf8cbf4\n",
      "  \u001b[31m   \u001b[0m error: command 'cmake' failed: No such file or directory\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[31m  ERROR: Failed building wheel for pyarrow\u001b[0m\u001b[31m\n",
      "\u001b[0mFailed to build pyarrow\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (pyarrow)\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install datasets torch transformers accelerate evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae5ed3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "! export 'PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e731df",
   "metadata": {},
   "source": [
    "### Dataset metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11d73a77-36f3-4f61-aedd-dcec12fca62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/latest/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset_builder\n",
    "ds_builder = load_dataset_builder(\"google/code_x_glue_ct_code_to_text\", \"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e3b2d32-8bf4-479c-be3b-a544ea7a75a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': Value(dtype='int32', id=None),\n",
       " 'repo': Value(dtype='string', id=None),\n",
       " 'path': Value(dtype='string', id=None),\n",
       " 'func_name': Value(dtype='string', id=None),\n",
       " 'original_string': Value(dtype='string', id=None),\n",
       " 'language': Value(dtype='string', id=None),\n",
       " 'code': Value(dtype='string', id=None),\n",
       " 'code_tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
       " 'docstring': Value(dtype='string', id=None),\n",
       " 'docstring_tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
       " 'sha': Value(dtype='string', id=None),\n",
       " 'url': Value(dtype='string', id=None)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_builder.info.features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33925a3d-d809-4812-b140-5b703c0112ea",
   "metadata": {},
   "source": [
    "## Load the dataset\n",
    "\n",
    "Skip examples to make training time feasable on CSU dept machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a734008-a354-4965-acf9-23f370dd5bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 251820/251820 [00:09<00:00, 27704.92 examples/s]\n",
      "Generating validation split: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13914/13914 [00:00<00:00, 24658.34 examples/s]\n",
      "Generating test split: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 14918/14918 [00:00<00:00, 24102.56 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"google/code_x_glue_ct_code_to_text\", \"python\")\n",
    "dataset['train'] = dataset['train'].skip(180000)\n",
    "dataset['test'] = dataset['test'].skip(7800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "684b0710-f3c4-4eda-8e23-ef4f99588353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': (71820, 12), 'validation': (13914, 12), 'test': (7118, 12)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1411544b-84ee-44bd-9758-15e2b149ce99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': ['id',\n",
       "  'repo',\n",
       "  'path',\n",
       "  'func_name',\n",
       "  'original_string',\n",
       "  'language',\n",
       "  'code',\n",
       "  'code_tokens',\n",
       "  'docstring',\n",
       "  'docstring_tokens',\n",
       "  'sha',\n",
       "  'url'],\n",
       " 'validation': ['id',\n",
       "  'repo',\n",
       "  'path',\n",
       "  'func_name',\n",
       "  'original_string',\n",
       "  'language',\n",
       "  'code',\n",
       "  'code_tokens',\n",
       "  'docstring',\n",
       "  'docstring_tokens',\n",
       "  'sha',\n",
       "  'url'],\n",
       " 'test': ['id',\n",
       "  'repo',\n",
       "  'path',\n",
       "  'func_name',\n",
       "  'original_string',\n",
       "  'language',\n",
       "  'code',\n",
       "  'code_tokens',\n",
       "  'docstring',\n",
       "  'docstring_tokens',\n",
       "  'sha',\n",
       "  'url']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "152e71a9-5f32-4eda-9cfc-e9f971b12f20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 180000,\n",
       " 'repo': 'Tanganelli/CoAPthon3',\n",
       " 'path': 'coapthon/messages/option.py',\n",
       " 'func_name': 'Option.length',\n",
       " 'original_string': 'def length(self):\\n        \"\"\"\\n        Return the value length\\n\\n        :rtype : int\\n        \"\"\"\\n        if isinstance(self._value, int):\\n            return byte_len(self._value)\\n        if self._value is None:\\n            return 0\\n        return len(self._value)',\n",
       " 'language': 'python',\n",
       " 'code': 'def length(self):\\n        \"\"\"\\n        Return the value length\\n\\n        :rtype : int\\n        \"\"\"\\n        if isinstance(self._value, int):\\n            return byte_len(self._value)\\n        if self._value is None:\\n            return 0\\n        return len(self._value)',\n",
       " 'code_tokens': ['def',\n",
       "  'length',\n",
       "  '(',\n",
       "  'self',\n",
       "  ')',\n",
       "  ':',\n",
       "  'if',\n",
       "  'isinstance',\n",
       "  '(',\n",
       "  'self',\n",
       "  '.',\n",
       "  '_value',\n",
       "  ',',\n",
       "  'int',\n",
       "  ')',\n",
       "  ':',\n",
       "  'return',\n",
       "  'byte_len',\n",
       "  '(',\n",
       "  'self',\n",
       "  '.',\n",
       "  '_value',\n",
       "  ')',\n",
       "  'if',\n",
       "  'self',\n",
       "  '.',\n",
       "  '_value',\n",
       "  'is',\n",
       "  'None',\n",
       "  ':',\n",
       "  'return',\n",
       "  '0',\n",
       "  'return',\n",
       "  'len',\n",
       "  '(',\n",
       "  'self',\n",
       "  '.',\n",
       "  '_value',\n",
       "  ')'],\n",
       " 'docstring': 'Return the value length\\n\\n        :rtype : int',\n",
       " 'docstring_tokens': ['Return', 'the', 'value', 'length'],\n",
       " 'sha': '985763bfe2eb9e00f49ec100c5b8877c2ed7d531',\n",
       " 'url': 'https://github.com/Tanganelli/CoAPthon3/blob/985763bfe2eb9e00f49ec100c5b8877c2ed7d531/coapthon/messages/option.py#L80-L90'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33365edb",
   "metadata": {},
   "source": [
    "## Create Tokenizer\n",
    "\n",
    "Roberta Tokenizer creates byte-level Byte-Pair-Encoding, suitable for our base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ced56d7-23ed-4162-8d61-8b2b2275aaef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n",
      "0it [00:00, ?it/s]\n",
      "2024-12-06 04:38:04.381554: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, T5ForConditionalGeneration\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"Salesforce/codet5-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be9c322",
   "metadata": {},
   "source": [
    "## Preprocessing data\n",
    "\n",
    "Prefix given to match one of the applications of the pretrained model and improve performance. \n",
    "code_tokens used instead of 'code' because the code_tokens do not contain the docstring that the model is trying to generate. The code tokens are instead combined into a string in this step suitable for the model's tokenization process. Use -100 for label on padding tokens so that they do not cause reduced model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71110ec1-3767-4c62-ae91-14f71ca86bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"Summarize Python: \"\n",
    "def preprocess(samples):\n",
    "    codestrings = samples['code_tokens']\n",
    "    \n",
    "    \n",
    "    docstrings = samples['docstring']\n",
    "\n",
    "    inputs = []\n",
    "    for codestring in codestrings:\n",
    "        codestring = ' '.join(codestring)\n",
    "        inputs.append(prefix + codestring)\n",
    "        \n",
    "    model_inputs = tokenizer(inputs, padding=\"max_length\", truncation=True)\n",
    "    labels = tokenizer(docstrings, padding=\"max_length\", truncation=True).input_ids\n",
    "\n",
    "    labels_with_ignore_index = []\n",
    "    for labels_example in labels:\n",
    "        labels_example = [label if label != 0 else -100 for label in labels_example]\n",
    "        labels_with_ignore_index.append(labels_example)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels_with_ignore_index\n",
    "\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ecfeb3e-8549-4b83-9ea2-844208a17092",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 71820/71820 [00:47<00:00, 1512.51 examples/s]\n",
      "Map: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13914/13914 [00:10<00:00, 1322.24 examples/s]\n",
      "Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7118/7118 [00:04<00:00, 1472.07 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(preprocess, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0113edd1",
   "metadata": {},
   "source": [
    "## Dataset loaders\n",
    "batch size is sized to not run out of memory on CSU dept machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "532eae99-d518-40f3-8208-5aa8a77853f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataset.set_format(type=\"torch\", columns=['input_ids', 'attention_mask', 'labels'])\n",
    "train_dataloader = DataLoader(dataset['train'], shuffle=True, batch_size=16)\n",
    "valid_dataloader = DataLoader(dataset['validation'], batch_size=8)\n",
    "test_dataloader = DataLoader(dataset['test'], batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de53719",
   "metadata": {},
   "source": [
    "## Training columns\n",
    "attention_mask is included so that extra padding input_id's are not mistaken as actual input by model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1204ed0d-0536-455a-b833-90bd4487cfaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask', 'labels'])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_dataloader))\n",
    "print(batch.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0b2e64",
   "metadata": {},
   "source": [
    "## Example of decoding producing original docstring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30845957-cb94-4379-84fa-5ee98b6a0727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>Remove a relationship from one user to another, with the same caveats\\n        and behavior as adding a relationship.</s>'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = batch['labels'][0]\n",
    "tokenizer.decode([label for label in labels if label != -100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3055f656",
   "metadata": {},
   "source": [
    "## Base pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ab2ff88-3212-41c1-8774-fe6f308cb6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(\"Salesforce/codet5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e9552ae-03c5-478e-9796-3a670c086c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbfdcfa",
   "metadata": {},
   "source": [
    "## Hypr-parameters\n",
    "increasing these, particularly num_epochs results in extremely long training time on dept machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f6f78a0-fc68-4db1-b9ae-d5d1d29fce90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_scheduler\n",
    "num_epochs = 1\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf48a9f",
   "metadata": {},
   "source": [
    "## Backend processing device\n",
    "Ensure CUDA is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "671ded69-a650-42e7-ba93-5f7d772eb72b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32100, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32100, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32100, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=32100, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from accelerate.test_utils.testing import get_backend\n",
    "\n",
    "device, _, _ = get_backend() # automatically detects the underlying device type (CUDA, CPU, XPU, MPS, etc.)\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947b71a9",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b9f0701-5395-434d-86e4-9745ea5fd62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                                                                                                                                                                                                                          | 0/4489 [00:00<?, ?it/s]Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4489/4489 [40:11<00:00,  2.02it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51012cfa",
   "metadata": {},
   "source": [
    "## Save the trained model for future use and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7630e8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_directory = \".\"\n",
    "model.save_pretrained(save_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b44e06f",
   "metadata": {},
   "source": [
    "## Example of loading in dataset and using model for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e70c2714-ceb7-4069-8088-ca3496745c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['id', 'repo', 'path', 'func_name', 'original_string', 'language', 'code', 'code_tokens', 'docstring', 'docstring_tokens', 'sha', 'url'],\n",
      "    num_rows: 13914\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"google/code_x_glue_ct_code_to_text\", \"python\")\n",
    "print(dataset['validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f14f8cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code: ['def', 'wrap_deepmind', '(', 'env', ',', 'episode_life', '=', 'True', ',', 'clip_rewards', '=', 'True', ',', 'frame_stack', '=', 'False', ',', 'scale', '=', 'False', ')', ':', 'if', 'episode_life', ':', 'env', '=', 'EpisodicLifeEnv', '(', 'env', ')', 'if', \"'FIRE'\", 'in', 'env', '.', 'unwrapped', '.', 'get_action_meanings', '(', ')', ':', 'env', '=', 'FireResetEnv', '(', 'env', ')', 'env', '=', 'WarpFrame', '(', 'env', ')', 'if', 'scale', ':', 'env', '=', 'ScaledFloatFrame', '(', 'env', ')', 'if', 'clip_rewards', ':', 'env', '=', 'ClipRewardEnv', '(', 'env', ')', 'if', 'frame_stack', ':', 'env', '=', 'FrameStack', '(', 'env', ',', '4', ')', 'return', 'env']\n"
     ]
    }
   ],
   "source": [
    "test_example = dataset['validation'][32]\n",
    "print(\"Code:\", test_example['code_tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dd08e985",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(save_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d376b5",
   "metadata": {},
   "source": [
    "### Ensure that the sample input is the joined tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "29de9d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated docstring: Wrap an environment into a deepmind environment.\n",
      "\n",
      "    :param env: The environment\n"
     ]
    }
   ],
   "source": [
    "test_ex = ' '.join(test_example['code_tokens'])\n",
    "input_ids = tokenizer(test_ex, return_tensors='pt').input_ids\n",
    "\n",
    "outputs = model.generate(input_ids)\n",
    "print(\"Generated docstring:\", tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "78485e42-ae81-47b1-9a10-2cfe301fccb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True docstring:  Configure environment for DeepMind-style Atari.\n"
     ]
    }
   ],
   "source": [
    "print(\"True docstring: \", test_example['docstring'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031f7a73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2db7dbda",
   "metadata": {},
   "source": [
    "Simple Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1390c88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_evaluation(model, tokenizer, validation_dataset, num_samples=100):\n",
    "    \"\"\"\n",
    "    Accuracy is measured using token overlap it will create a token for each word for the reference the test and then tokenize\n",
    "    the generated and then comparing each other to get the score. \n",
    "\n",
    "    as well it will generate a extact one.\n",
    "\n",
    "\n",
    "    Evaluate the model's performance using token overlap metrics.\n",
    "    Args:\n",
    "    - model: Trained T5 model.\n",
    "    - tokenizer: Tokenizer for the model.\n",
    "    - validation_dataset: Validation dataset containing 'code_tokens' and 'docstring'.\n",
    "    - num_samples: Number of samples to evaluate (default is 100).\n",
    "\n",
    "    Returns:\n",
    "    - accuracy: Proportion of exact matches between predictions and references.\n",
    "    - avg_overlap: Average token overlap percentage.\n",
    "    \"\"\"\n",
    "\n",
    "    total_overlap = 0\n",
    "    exact_matches = 0\n",
    "    total_samples = min(num_samples, len(validation_dataset))\n",
    "\n",
    "    for i in range(total_samples):\n",
    "        example = validation_dataset[i]\n",
    "\n",
    "        # Prepare input\n",
    "        input_text = \" \".join(example[\"code_tokens\"])\n",
    "        input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
    "\n",
    "        # Generate prediction\n",
    "        outputs = model.generate(input_ids)\n",
    "        generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "        # Get reference\n",
    "        reference = example[\"docstring\"]\n",
    "\n",
    "        # Token overlap\n",
    "        pred_tokens = set(generated_text.split())\n",
    "        ref_tokens = set(reference.split())\n",
    "        overlap = len(pred_tokens & ref_tokens) / len(ref_tokens) if ref_tokens else 0\n",
    "        total_overlap += overlap\n",
    "\n",
    "        # Exact match\n",
    "        if generated_text.strip() == reference.strip():\n",
    "            exact_matches += 1\n",
    "\n",
    "    accuracy = exact_matches / total_samples\n",
    "    avg_overlap = total_overlap / total_samples\n",
    "\n",
    "    return accuracy, avg_overlap\n",
    "\n",
    "\n",
    "\n",
    "validation_dataset = dataset[\"validation\"][:100]  # Load a subset for faster evaluation\n",
    "accuracy, avg_overlap = simple_evaluation(model, tokenizer, validation_dataset)\n",
    "print(f\"Accuracy (Exact Matches): {accuracy * 100:.2f}%\")\n",
    "print(f\"Average Token Overlap: {avg_overlap * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04800a1d",
   "metadata": {},
   "source": [
    "Adding Rouge Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ce7f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "from transformers import T5Tokenizer\n",
    "\n",
    "# Load ROUGE metric\n",
    "rouge_metric = load_metric(\"rouge\")\n",
    "\n",
    "def evaluate_rouge(model, tokenizer, validation_dataset, num_samples=100):\n",
    "    \"\"\"\n",
    "\n",
    "    Accuracy: Measures overlap of n-grams and longest common subsequences (LCS) between generated and reference texts.\n",
    "    Variants like ROUGE-1, ROUGE-2, and ROUGE-L capture different levels of granularity:\n",
    "    ROUGE-1: Unigram overlap.\n",
    "    ROUGE-2: Bigram overlap.\n",
    "    ROUGE-L: Longest common subsequence, which captures sentence structure.\n",
    "    ROUGE-L will reward sequences even if the prediction misses some intermediate words.\n",
    "\n",
    "    Evaluate the model using ROUGE scores.\n",
    "\n",
    "    Args:\n",
    "    - model: Trained T5 model.\n",
    "    - tokenizer: Tokenizer for the model.\n",
    "    - validation_dataset: Dataset containing 'code_tokens' and 'docstring'.\n",
    "    - num_samples: Number of samples to evaluate.\n",
    "\n",
    "    Returns:\n",
    "    - rouge_scores: Dictionary with average ROUGE scores (ROUGE-1, ROUGE-2, ROUGE-L).\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    references = []\n",
    "\n",
    "    # Evaluate on a subset of the validation data\n",
    "    total_samples = min(num_samples, len(validation_dataset))\n",
    "    for i in range(total_samples):\n",
    "        example = validation_dataset[i]\n",
    "\n",
    "        # Prepare input text\n",
    "        input_text = \" \".join(example[\"code_tokens\"])\n",
    "        input_ids = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True).input_ids\n",
    "\n",
    "        # Generate prediction\n",
    "        outputs = model.generate(input_ids)\n",
    "        generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "        # Append results\n",
    "        predictions.append(generated_text)\n",
    "        references.append(example[\"docstring\"])\n",
    "\n",
    "    # Compute ROUGE\n",
    "    rouge_results = rouge_metric.compute(predictions=predictions, references=references)\n",
    "\n",
    "    # Extract relevant ROUGE scores\n",
    "    rouge_scores = {\n",
    "        \"ROUGE-1\": rouge_results[\"rouge1\"].mid.fmeasure,\n",
    "        \"ROUGE-2\": rouge_results[\"rouge2\"].mid.fmeasure,\n",
    "        \"ROUGE-L\": rouge_results[\"rougeL\"].mid.fmeasure\n",
    "    }\n",
    "\n",
    "    return rouge_scores\n",
    "\n",
    "validation_dataset = dataset[\"validation\"][:100] \n",
    "rouge_scores = evaluate_rouge(model, tokenizer, validation_dataset)\n",
    "print(\"ROUGE Evaluation Scores:\")\n",
    "print(f\"ROUGE-1: {rouge_scores['ROUGE-1']:.4f}\")\n",
    "print(f\"ROUGE-2: {rouge_scores['ROUGE-2']:.4f}\")\n",
    "print(f\"ROUGE-L: {rouge_scores['ROUGE-L']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea3749e",
   "metadata": {},
   "source": [
    "adding Bleu Evalutation Method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92164b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "from transformers import T5Tokenizer\n",
    "\n",
    "# Load BLEU metric\n",
    "bleu_metric = load_metric(\"bleu\")\n",
    "\n",
    "def evaluate_bleu(model, tokenizer, validation_dataset, num_samples=100):\n",
    "    \"\"\"\n",
    "    Evaluate the model using BLEU scores. \n",
    "\n",
    "    Args:\n",
    "    - model: Trained T5 model.\n",
    "    - tokenizer: Tokenizer for the model.\n",
    "    - validation_dataset: Dataset containing 'code_tokens' and 'docstring'.\n",
    "    - num_samples: Number of samples to evaluate.\n",
    "\n",
    "    Returns:\n",
    "    - bleu_score: Average BLEU score for the evaluated samples.\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    references = []\n",
    "\n",
    "    total_samples = min(num_samples, len(validation_dataset))\n",
    "    for i in range(total_samples):\n",
    "        example = validation_dataset[i]\n",
    "\n",
    "        # Prepare input text\n",
    "        input_text = \" \".join(example[\"code_tokens\"])\n",
    "        input_ids = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True).input_ids\n",
    "\n",
    "        # Generate prediction\n",
    "        outputs = model.generate(input_ids)\n",
    "        generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "        # Append results\n",
    "        predictions.append(generated_text.split())  # Tokenize the generated text\n",
    "        references.append([example[\"docstring\"].split()])  # BLEU expects list of references\n",
    "\n",
    "    # Compute BLEU\n",
    "    bleu_results = bleu_metric.compute(predictions=predictions, references=references)\n",
    "\n",
    "    return bleu_results[\"bleu\"]\n",
    "\n",
    "validation_dataset = dataset[\"validation\"][:100]  # Use a subset for faster evaluation\n",
    "bleu_score = evaluate_bleu(model, tokenizer, validation_dataset)\n",
    "print(f\"BLEU Score: {bleu_score:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
